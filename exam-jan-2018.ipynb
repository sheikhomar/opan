{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">.summary {\n",
       "  border: solid 1px green !important;\n",
       "  background: #cdffd8 !important;\n",
       "  padding: 10px !important;\n",
       "  border-radius: 2px !important;\n",
       "}\n",
       "\n",
       ".insight {\n",
       "  border: solid 1px green !important;\n",
       "  background: #cdffd8 !important;\n",
       "  padding: 10px !important;\n",
       "  border-radius: 2px !important;\n",
       "}\n",
       "\n",
       ".sidenote {\n",
       "  border: solid 1px green !important;\n",
       "  background: #cdffd8 !important;\n",
       "  padding: 10px !important;\n",
       "  border-radius: 2px !important;\n",
       "}\n",
       "\n",
       ".warning {\n",
       "  border: solid 1px #8a6d3b !important;\n",
       "  background: #fcf8e3 !important;\n",
       "  padding: 10px !important;\n",
       "  border-radius: 2px !important;\n",
       "}\n",
       "\n",
       ".green {\n",
       "  color: #006600 !important;\n",
       "}\n",
       "\n",
       ".red {\n",
       "  color: #cc0000 !important;\n",
       "}\n",
       "\n",
       ".simplex-tableaux {\n",
       "    font-size: 13pt !important;\n",
       "}\n",
       "\n",
       ".last-row td {\n",
       "    border-top: solid 1px Black !important;\n",
       "}\n",
       "\n",
       ".smallest-value {\n",
       "    background-color: Green !important;\n",
       "    color: White !important;\n",
       "    font-weight: bold !important;\n",
       "}</style>Stylesheet \"styles.css\" loaded."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sympy as sy\n",
    "import utils as utils\n",
    "from fractions import Fraction\n",
    "from func import Func\n",
    "import func\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Inline plotting\n",
    "%matplotlib inline\n",
    "\n",
    "# Make sympy print pretty math expressions\n",
    "sy.init_printing()\n",
    "\n",
    "utils.load_custom_styles()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/exam-jan-2018/ex1.png\" width=\"800\" />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<img src=\"figures/exam-jan-2018/ex1a.png\" width=\"800\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/exam-jan-2018/sol-ex1a.jpg\" width=\"500\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<img src=\"figures/exam-jan-2018/ex1b.png\" width=\"800\" />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using following procedure:\n",
    "\n",
    "- Step 1: Convert inequalities to equalites using slack variables\n",
    "- Step 2: Convert objective function to an equally.\n",
    "- Step 3: Construct the initial simplex tableaux\n",
    "- Step 4: Find the pivot column. The pivot column can be found by looking at the smallest value at the bottom row. In this case, we have two pivot columns and we select the first. Next, find the pivot row. Pick the smallest of smallest of $b_i / a_{i1}$. \n",
    "- Step 5: Make the pivot column to a basis column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/exam-jan-2018/sol-ex1b.jpg\" width=\"500\" />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x_1   x_2   s_1   s_2   s_3    b    \n",
      "|   1     2     1     0     0    12   | s_1\n",
      "|   1     5     0     1     0    25   | s_2\n",
      "|   1     0     0     0     1     6   | s_3\n",
      "|  -1    -1     0     0     0     0   |\n",
      "Current solution: {'x_1': 0, 'x_2': 0, 's_1': Fraction(12, 1), 's_2': Fraction(25, 1), 's_3': Fraction(6, 1), 'z': 0}\n",
      "\n",
      "   x_1   x_2   s_1   s_2   s_3    b    \n",
      "|   1     2     1     0     0    12   | s_1\n",
      "|   1     5     0     1     0    25   | s_2\n",
      "|   1     0     0     0     1     6   | s_3\n",
      "|  -1    -1     0     0     0     0   |\n",
      "\n",
      "There are negative elements in the bottom row, so the current solution is not optimal. Thus, pivot to improve the current solution. The entering variable is x_1 and the departing variable is s_3.\n",
      "\n",
      "\n",
      "Perform elementary row operations until the pivot is one and all other elements in the entering column are zero.\n",
      "\n",
      "   x_1   x_2   s_1   s_2   s_3    b    \n",
      "|   0     2     1     0    -1     6   | s_1\n",
      "|   0     5     0     1    -1    19   | s_2\n",
      "|   1     0     0     0     1     6   | x_1\n",
      "|   0    -1     0     0     1     6   |\n",
      "Current solution: {'x_1': Fraction(6, 1), 'x_2': 0, 's_1': Fraction(6, 1), 's_2': Fraction(19, 1), 's_3': 0, 'z': Fraction(6, 1)}\n",
      "\n",
      "   x_1   x_2   s_1   s_2   s_3    b    \n",
      "|   0     2     1     0    -1     6   | s_1\n",
      "|   0     5     0     1    -1    19   | s_2\n",
      "|   1     0     0     0     1     6   | x_1\n",
      "|   0    -1     0     0     1     6   |\n",
      "\n",
      "There are negative elements in the bottom row, so the current solution is not optimal. Thus, pivot to improve the current solution. The entering variable is x_2 and the departing variable is s_1.\n",
      "\n",
      "\n",
      "Perform elementary row operations until the pivot is one and all other elements in the entering column are zero.\n",
      "\n",
      "   x_1   x_2   s_1   s_2   s_3    b    \n",
      "|   0     1    1/2    0   -1/2    3   | x_2\n",
      "|   0     0   -5/2    1    3/2    4   | s_2\n",
      "|   1     0     0     0     1     6   | x_1\n",
      "|   0     0    1/2    0    1/2    9   |\n",
      "Current solution: {'x_1': Fraction(6, 1), 'x_2': Fraction(3, 1), 's_1': 0, 's_2': Fraction(4, 1), 's_3': 0, 'z': Fraction(9, 1)}\n",
      "\n",
      "That's all folks!\n"
     ]
    }
   ],
   "source": [
    "from simplex import SimplexSolver \n",
    "A = [[1, 2],\n",
    "     [1, 5],\n",
    "     [1, 0]]\n",
    "b = [12, 25, 6]\n",
    "c = [1, 1]\n",
    "solver = SimplexSolver()\n",
    "res = solver.run_simplex(A, b, c, prob='max', enable_msg=True, latex_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x_1': Fraction(6, 1),\n",
       " 'x_2': Fraction(3, 1),\n",
       " 's_1': 0,\n",
       " 's_2': Fraction(4, 1),\n",
       " 's_3': 0,\n",
       " 'z': Fraction(9, 1)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum for $f$ can be found using SciPy Linear Programming algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Optimal solution: "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$$x_1 = 6, x_2 = 3, s_1 = 0, s_2 = 4, s_3 = 0, M=9$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import linprog as lp\n",
    "\n",
    "A = [[1, 2],\n",
    "     [1, 5],\n",
    "     [1, 0]]\n",
    "b = [12, 25, 6]\n",
    "c = [1, 1]\n",
    "\n",
    "res = lp.maximise(A, b, c)\n",
    "lp.pretty_print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum is $f(6, 3) = 6+3=9$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<img src=\"figures/exam-jan-2018/ex1c.png\" width=\"800\" />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that at least one of the extreme points or corners of the feasible area corresponds to an optimal solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/exam-jan-2018/theorem-6.png\" width=\"800\" />\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing inequality ii) moves only one of the extreme points; from $(0, 5)$ to $(0, 6)$. This is because only the $y$-intersect is changed and not the slope of the corresponding line.\n",
    "\n",
    "Evaluating our objective function on this new extreme point, we get $f(0, 6) = 0+6 = 6$. This does not change the maximum for $f$ which was $f(6, 3)=6+3=9$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/exam-jan-2018/ex2a.png\" width=\"800\" />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient of $f$:\n",
    "$$\n",
    "\\nabla f = \n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial f}{\\partial x_1} \\\\\n",
    "\\frac{\\partial f}{\\partial x_2} \\\\\n",
    "\\frac{\\partial f}{\\partial x_3} \\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "1 \\\\\n",
    "-1 \\\\\n",
    "-1 \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient of $f$ gives the partial derivatives in each dimensions. The partial derivative $\\frac{\\partial f}{\\partial x_1}$ gives us the slope of $f$ in the positive $x_1$ direction, $\\frac{\\partial f}{\\partial x_2}$ gives us the slope of $f$ in the positive $x_2$ direction and $\\frac{\\partial f}{\\partial x_3}$ gives us the slope in the positive $x_3$ direction.\n",
    "\n",
    "Instead of fixing the direction, we can generalise the partial derivatives to compute the slope in any direction that we want. Like the partial derivative, we can define the directional derivative as follows:\n",
    "\n",
    "\\begin{align*}\n",
    "D_{\\mathbf{d}} f(\\mathbf{x}) = \\lim_{h \\to 0} \\frac{f(\\mathbf{x} + h \\mathbf{d}) - f(\\mathbf{x})}{h}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that we can dot the gradient with the direction vector $\\mathbf{d}$ to find the directional derivative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\left[\\begin{matrix}1\\\\-1\\\\-1\\end{matrix}\\right]$$"
      ],
      "text/plain": [
       "⎡1 ⎤\n",
       "⎢  ⎥\n",
       "⎢-1⎥\n",
       "⎢  ⎥\n",
       "⎣-1⎦"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1, x2, x3 = sy.symbols('x1, x2, x3')\n",
    "f = Func(x1 - x2 - x3, (x1, x2, x3))\n",
    "fg = f.gradient()\n",
    "fg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The directional derivative:\n",
    "$$\n",
    "\\frac{\\partial f(\\mathbf{x})}{\\partial \\mathbf{d}} \n",
    "= \\nabla f(\\mathbf{x})^T \\mathbf{d}\n",
    "=\n",
    "[1, -1, -1]\n",
    "\\begin{bmatrix}\n",
    "2 \\\\\n",
    "3 \\\\\n",
    "4 \\\\\n",
    "\\end{bmatrix}\n",
    "= -5\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\left[\\begin{matrix}-5\\end{matrix}\\right]$$"
      ],
      "text/plain": [
       "[-5]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fg.T * sy.Matrix([[2], [3], [4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<img src=\"figures/exam-jan-2018/ex2b.png\" width=\"800\" />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it is an optimisation problem with equality constraints, we can use the Lagrangian method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Lagrangian method is given as follows:\n",
    "1. Define the Lagrangian function by incoporating the constraint into the objective function\n",
    "$$\n",
    "L(\\mathbf{x}, \\lambda) = f(\\mathbf{x}) - \\lambda ( h(\\mathbf{x}) - c  )\n",
    "$$\n",
    "where $\\lambda$ is the Lagrangian multiplier associated with the contraint. When the contraint holds i.e., when $h(\\mathbf{x})=c$ then $L(\\mathbf{x}, \\lambda)=f(\\mathbf{x})$\n",
    "2. Since $L(\\mathbf{x}, \\lambda)$ is an unconstraint objective function, we can optimise it by finding its FONC i.e., taking the derivative and setting it zero.\n",
    "3. Now, we get a system of linear equations. Solving it will yield the points where the objective function is maximised or minimised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2, x3 = sy.symbols('x1, x2, x3')\n",
    "\n",
    "f = x1 - x2 - x3\n",
    "h = Fraction(1, 4) * x1**2 + Fraction(1, 9) * x2**2 + Fraction(1, 3) * x3**2 - 1\n",
    "F = Func(f, (x1, x2, x3), constraints=[h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "points, lambdas = F.solve_lagrangian()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/latex": [
       "$$\\left [ \\left ( -1, \\quad \\frac{9}{4}, \\quad \\frac{3}{4}\\right ), \\quad \\left ( 1, \\quad - \\frac{9}{4}, \\quad - \\frac{3}{4}\\right )\\right ]$$"
      ],
      "text/plain": [
       "[(-1, 9/4, 3/4), (1, -9/4, -3/4)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluting f(-1, 9/4, 3/4) = -4.00000000000000\n",
      "Evaluting f(1, -9/4, -3/4) = 4.00000000000000\n"
     ]
    }
   ],
   "source": [
    "F.evalf(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function $f$ is minimum at point $(-1, 9/4, 3/4)$ and maximum at point $(1, -9/4, -3/4)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer the following with ONE sentence per question.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) What is the main difference between the Newton and Quasi-Newton method?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Quasi-Newton method uses an approximation of the inverse of the Hessian instead of the true inverse which is done in the Newton method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src=\"figures/lecture-10/quasi-newton-intro.png\" width=\"600\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "**b) What is discrete optimization? Name one example of a well-known discrete optimization problem.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the input space (optimisation variables) is finite then we have a discrete optimisation, otherwise we have a continuous. The travelling salesman problem is an well-known example of a discrete optimisation problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**c) What is the main feature of global search methods?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global search methods have built-in mechanisms that allow them to escape local minima although they do not gurantee to find the global optimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<img src=\"figures/exam-jan-2018/ex3d.png\" width=\"800\" />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Particle Swarm: Stochastic, Global Search, Population of candidate solution\n",
    "- Simulated Annealing: Stochastic, Global Search\n",
    "- Quasi-Newton: Deterministic\n",
    "- Newton: Deterministic\n",
    "- Genetic Algorithms: Stochastic, Global Search, Population-based\n",
    "- Conjugate Gradient: Deterministic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<img src=\"figures/exam-jan-2018/ex3e.png\" width=\"800\" />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<img src=\"figures/exam-jan-2018/ex3e1.png\" width=\"800\" />\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the turle can move in three distinct directions, we can use 2 bits to represent each direction; 00 = Up, 01 = Right, 10 = Left. A turtle path  consists of 5 steps, so each path (candidate solution) can be represented as a chromosome of length 10. Here are some examples of chromosomes that corresponds to turtle paths:\n",
    "\n",
    "- `00 01 01 00 10` corresponds to the first path  \n",
    "- `00 10 00 00 10` corresponds to the second path\n",
    "- `00 00 00 00 01` corresponds to the third path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<img src=\"figures/exam-jan-2018/ex3e2.png\" width=\"800\" />\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the Manhattan distance as the objective function. Here are the costs of the three example paths:\n",
    "- `cost(example1) = 2`\n",
    "- `cost(example2) = 3`\n",
    "- `cost(example3) = 0`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<img src=\"figures/exam-jan-2018/ex3e3.png\" width=\"800\" />\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have two parents; A and B. A's chromosome is `00 01 01 00 10` and B's chromosome is `01 00 00 01 01`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single point crossover works as follows:\n",
    "- Randomly pick a crossover position\n",
    "- Generate two children by swapping the chromosomes of the two parents\n",
    "\n",
    "For example, if we pick crossover position 4, then single-point crossover yields two children\n",
    "- Child 1 with the chromosome `00 01 00 01 01`\n",
    "- Child 2 with the chromosome `01 00 01 00 10`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<img src=\"figures/exam-jan-2018/ex3e4.png\" width=\"800\" />\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One bit of Child 1's chromosome `00 01 00 01 01` may be flipped with a low probability to `00 01 00 01 00`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<img src=\"figures/exam-jan-2018/ex3e5.png\" width=\"800\" />\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genetic_algorith(P, N, num_generations):\n",
    "    for i in range(num_generations):\n",
    "        compute_individual_fitness_of(P)\n",
    "        mating_pool = select_mating_pool(P)\n",
    "        offspring = cross_over(mating_pool)\n",
    "        P = mutate(offspring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Compute the fitness of each individual in the population. Fitness is based on the objective function value of that candidate solution.\n",
    "2. Select individuals based on their fitness in the population. For example, we can select chromosomes into the mating pool with probabilities proportional to their fitness.\n",
    "3. Perform crossover operation on individuals in the mating pool to create the next generation of individuals\n",
    "4. Perform mutation i.e., alters bits in the chromosome with low probability\n",
    "5. Use the offspring as the population in the next generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Exercise 4\n",
    "<img src=\"figures/exam-jan-2018/ex4.png\" width=\"800\" />\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0, 1, 1, 3, 3, 4, 4],\n",
    "              [1, 0, 1, 1, 2, 4, 2]])\n",
    "l = np.array( [1, 1, 1, 2, 2, 2, 2])\n",
    "X_test = np.array([[1, 3, 2],\n",
    "                   [2, 0, 1]])\n",
    "C1 = X[:,0:3]\n",
    "C2 = X[:,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) The Nearest Class Centroid (NCC) classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the class centroid for each class\n",
    "mu1 = np.mean(C1, axis=1).reshape(-1, 1)\n",
    "mu2 = np.mean(C2, axis=1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute distances between the centroids and the test samples\n",
    "pair_dist_mu1 = pairwise_distances(X_test.T, mu1.T)\n",
    "pair_dist_mu2 = pairwise_distances(X_test.T, mu2.T)\n",
    "pair_dist = np.concatenate([pair_dist_mu1, pair_dist_mu2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classify using the lowest distance\n",
    "np.argmin(pair_dist, axis=1)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that $\\mathbf{x}_8$ and $\\mathbf{x}_{10}$ are assigned label 1 and $\\mathbf{x}_9$ gets label 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**b) The Nearest Neighbor Classifier (using only one neighbor)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0, 1, 1, 3, 3, 4, 4],\n",
    "              [1, 0, 1, 1, 2, 4, 2]])\n",
    "X_test = np.array([[1, 3, 2],\n",
    "                   [2, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 1]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifications = []\n",
    "for i in range(X_test.shape[1]):\n",
    "    x_i = X_test[:,i].reshape(-1, 1)\n",
    "    # Compute the distance each sample in the training set\n",
    "    pair_dist = pairwise_distances(X.T, x_i.T).reshape(-1)\n",
    "    \n",
    "    # Assign the label of the closest sample\n",
    "    index = np.argmin(pair_dist, axis=0)\n",
    "    label = l[index]\n",
    "    \n",
    "    classifications.append(label)\n",
    "classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The samples $\\mathbf{x}_8$ and $\\mathbf{x}_{10}$ are assigned label 1 and $\\mathbf{x}_9$ gets label 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<img src=\"figures/exam-jan-2018/ex4c.png\" width=\"800\" />\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the class-conditional probabilities in multiple steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Compute the mean vector associated with each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = np.mean(C1, axis=1).reshape(-1, 1)\n",
    "m2 = np.mean(C2, axis=1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Compute $\\lVert \\mathbf{x}_i - \\mathbf{m}_k \\rVert^{-2}_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dist(samples):\n",
    "    N = samples.shape[1]\n",
    "    results = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        x_i = samples[:,i]\n",
    "        results[i] = 1/ np.dot(x_i, x_i)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1_num = calc_dist(X_test - m1)\n",
    "C2_num = calc_dist(X_test - m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Compute the class-conditional probabilities $p(\\mathbf{x} \\mid c_k)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_x_c1 = C1_num / (C1_num + C2_num)\n",
    "p_x_c2 = C2_num / (C1_num + C2_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Compute the prior probabilities for the classes. We can compute the prior probability for each class $c_k$ as follows:\n",
    "\n",
    "$$\n",
    "P(c_k) = \\frac{N_k}{\\sum_l^K N_l}\n",
    "$$\n",
    "where $N_k$ is the number of samples in class $c_k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "N1 = C1.shape[1]\n",
    "N2 = C2.shape[1]\n",
    "N_sum = N1 + N2\n",
    "\n",
    "P_c1 = N1/N_sum\n",
    "P_c2 = N2/N_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: We can now compute conditional probability, which has the following formula (Bayes' formula):\n",
    "\n",
    "$$\n",
    "P(c_k \\mid \\mathbf{x}) = \\frac{p(\\mathbf{x} \\mid c_k) P(c_k)}{p(\\mathbf{x})}\n",
    "$$\n",
    "where\n",
    "$$\n",
    "p(\\mathbf{x}) = \\sum_{k=1}^K p(\\mathbf{x} \\mid c_k) P(c_k)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $p(\\mathbf{x})$ is the same for when computing $P(c_k\\mid \\mathbf{x})$, it is not necessary to compute it when we want to use the conditional probability to classify new samples. Therefore, we omit the division:\n",
    "$$\n",
    "P(c_k \\mid \\mathbf{x}) = p(\\mathbf{x} \\mid c_k) P(c_k)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_c1_x = p_x_c1 * P_c1\n",
    "P_c2_x = p_x_c2 * P_c2\n",
    "\n",
    "# Create a matrix so we can easily compute argmin\n",
    "P_ck_x = np.concatenate([[P_c1_x], \n",
    "                         [P_c2_x]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Once we have the condition probabilities, we can use Bayes' Decision Rule to classify our samples $X$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Classification Result: \n",
       "$$\n",
       "\\mathbf{x}_{8} \\to 1  \\\\ \n",
       "\\mathbf{x}_{9} \\to 2  \\\\ \n",
       "\\mathbf{x}_{10} \\to 1  \\\\ \n",
       "$$"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.argmax(P_ck_x, axis=0)+1\n",
    "out = 'Classification Result: \\n$$\\n'\n",
    "for i, label in enumerate(labels):\n",
    "    out += '\\mathbf{{x}}_{{{}}} \\\\to {}  \\\\\\\\ \\n'.format(i+8, label)\n",
    "out += '$$'\n",
    "HTML(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**d) Compare (qualitatively) the decision functions obtained by using the NCC classifier and the above\n",
    "Bayes-based classification scheme.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Their decision functions are almost the same. NCC classifier can be seen as a Bayes-based classifier with two assumptions:\n",
    "1. The samples in each class follow a unimodal normal distribution with identity matrix as the covariant matrix, and\n",
    "2. All classes have equal probability\n",
    "\n",
    "Since the prior probability of class 2 is larger than class 1, the decision boundary for the Bayes-based classifier is moved slightly to the left compared to NCC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/exam-jan-2018/ex5a.png\" width=\"800\" />\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/exam-jan-2018/sol-ex5a.jpg\" width=\"600\" />\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<img src=\"figures/exam-jan-2018/ex5b.png\" width=\"800\" />\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify the proof, we ignore the bias terms, use the identify function as the activation function for all neurons and have only a single neuron in the output layer.\n",
    "\n",
    "Suppose we have a two-layer network with a single output. The output of this network is:\n",
    "$$\n",
    "o = \\mathbf{w}^T \\mathbf{x}\n",
    "$$\n",
    "\n",
    "Now, suppose we have a four-layer network (two hidden layers). The output of this network in steps.\n",
    "\n",
    "The output neuron is computed:\n",
    "\n",
    "$$\n",
    "o_{ML} = \\mathbf{w}^{(3)T} \\mathbf{h}_2\n",
    "$$\n",
    "\n",
    "The $\\mathbf{h}_2$ is computed as follows:\n",
    "\n",
    "$$\n",
    "\\mathbf{h}_2 = \\mathbf{W}^{(2)T} \\mathbf{h}_1\n",
    "$$\n",
    "\n",
    "The $\\mathbf{h}_1$ is computed as follows:\n",
    "\n",
    "$$\n",
    "\\mathbf{h}_1 = \\mathbf{W}^{(1)T} \\mathbf{x}\n",
    "$$\n",
    "\n",
    "Combining the three expressions, we get:\n",
    "\n",
    "$$\n",
    "o_{ML} = \\mathbf{w}^{(3)T} \\mathbf{W}^{(2)T} \\mathbf{W}^{(1)T} \\mathbf{x}\n",
    "$$\n",
    "\n",
    "The expression above can be simplied:\n",
    "$$\n",
    "o_{L} = \\mathbf{w}^T_{c} \\mathbf{x}\n",
    "$$\n",
    "where $\\mathbf{w}_{c} = \\mathbf{w}^{(3)T} \\mathbf{W}^{(2)T} \\mathbf{W}^{(1)T}$\n",
    "\n",
    "This shows that the four-layer network and two layer network are equivalent when the activation function for all neurons are linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<img src=\"figures/exam-jan-2018/ex5c.png\" width=\"800\" />\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result in b) shows that using only linear activation functions in an ANN means that the network is a linear function of the  input. This means it can only learn a linear decision function even though we have a network with large number of hidden layers. If our data is non-linear then we cannot model it. Therefore, non-linear activation functions are important in neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Exercise 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/exam-jan-2018/ex6a.png\" width=\"800\" />\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/exam-jan-2018/sol-ex6a.png\" width=\"400\" />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<img src=\"figures/exam-jan-2018/ex6b.png\" width=\"800\" />\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/exam-jan-2018/sol-ex6b.png\" width=\"400\" />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<img src=\"figures/exam-jan-2018/ex6c.png\" width=\"800\" />\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regions of ambiguity for one-vs-rest are coloured in grey:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/exam-jan-2018/sol-ex6c1.png\" width=\"400\" />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The region of ambiguity for one-vs-one is coloured in grey:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/exam-jan-2018/sol-ex6c2.png\" width=\"400\" />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
