{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 18: Maximum Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">.summary {\n",
       "  border: solid 1px green !important;\n",
       "  background: #cdffd8 !important;\n",
       "  padding: 10px !important;\n",
       "  border-radius: 2px !important;\n",
       "}\n",
       "\n",
       ".insight {\n",
       "  border: solid 1px green !important;\n",
       "  background: #cdffd8 !important;\n",
       "  padding: 10px !important;\n",
       "  border-radius: 2px !important;\n",
       "}\n",
       "\n",
       ".sidenote {\n",
       "  border: solid 1px green !important;\n",
       "  background: #cdffd8 !important;\n",
       "  padding: 10px !important;\n",
       "  border-radius: 2px !important;\n",
       "}\n",
       "\n",
       ".warning {\n",
       "  border: solid 1px #8a6d3b !important;\n",
       "  background: #fcf8e3 !important;\n",
       "  padding: 10px !important;\n",
       "  border-radius: 2px !important;\n",
       "}\n",
       "\n",
       ".green {\n",
       "  color: #006600 !important;\n",
       "}\n",
       "\n",
       ".red {\n",
       "  color: #cc0000 !important;\n",
       "}</style>Stylesheet \"styles.css\" loaded."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sympy as sy\n",
    "import utils as utils\n",
    "from fractions import Fraction\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Inline plotting\n",
    "%matplotlib inline\n",
    "\n",
    "# Make sympy print pretty math expressions\n",
    "sy.init_printing()\n",
    "\n",
    "utils.load_custom_styles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_classification(P, objective='max'):\n",
    "    labels = np.argmin(P, axis=0)+1 if objective=='min' else np.argmax(P, axis=0)+1\n",
    "    out = 'Classification Result: \\n$$\\n'\n",
    "    for i, label in enumerate(labels):\n",
    "        out += '\\mathbf{{x}}_{} \\\\to c_{}  \\\\\\\\ \\n'.format(i+1, label)\n",
    "    #['x{} => c{}'.format(i+1, label) for i, label in enumerate(labels)]\n",
    "    out += '$$'\n",
    "    return HTML(out)\n",
    "\n",
    "def calc_distances(X, mu_k, Sigma, k):\n",
    "    \"\"\"\n",
    "    Computes the distances between samples in X and\n",
    "    the mean mu_k.\n",
    "    \n",
    "    If no covariance matrix is given i.e., Sigma argument is None,\n",
    "    the Euclidean distance is used. Otherwse, the squared\n",
    "    Mahalanobis distance is used with the given \n",
    "    \"\"\"\n",
    "    if Sigma is None:\n",
    "        return np.linalg.norm(X - mu_k, axis=0)\n",
    "\n",
    "    # Compute the inverse of Sigma_k\n",
    "    S_inv = np.linalg.inv(Sigma[k])\n",
    "    N = X.shape[1]\n",
    "    result_vec = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        x_i = X[:,i].reshape(-1, 1)\n",
    "        x_i_centered = x_i - mu_k\n",
    "        # Compute the Mahalanobis distance for x_i\n",
    "        result_vec[i] = np.asscalar(x_i_centered.T.dot(S_inv).dot(x_i_centered))\n",
    "    return result_vec    \n",
    "\n",
    "def calc_conditional_prob(C, X, Sigma=None, verbose=True):\n",
    "    n_classes = len(C)\n",
    "    D = X.shape[0]\n",
    "    N_ck = []\n",
    "    p_x_ck_numerator = []\n",
    "\n",
    "    for k, c in enumerate(C):\n",
    "        N_ck.append(c.shape[1])\n",
    "        mu_k = np.mean(c, axis=1).reshape(-1, 1)\n",
    "        distances = calc_distances(X, mu_k, Sigma, k)\n",
    "        p_x_ck_numerator.append(np.exp(-distances))\n",
    "    P_ck = []\n",
    "    p_x_ck = []\n",
    "    P_ck_x = []\n",
    "    for i in range(n_classes):\n",
    "        P_ck.append(N_ck[i] / np.sum(N_ck))\n",
    "        p_x_ck.append(p_x_ck_numerator[i] / np.sum(p_x_ck_numerator, axis=0))\n",
    "        P_ck_x.append(p_x_ck[i] * P_ck[i])\n",
    "    if verbose:\n",
    "        for i in range(n_classes):\n",
    "            print('P(c{}): {}'.format(i+1, str(P_ck[i])))\n",
    "        print('---')\n",
    "        for i in range(n_classes):\n",
    "            print('p(x|c{}): {}'.format(i+1, utils.format_vector(p_x_ck[i])))\n",
    "        print('---')\n",
    "        for i in range(n_classes):\n",
    "            print('P(c{}|x): {}'.format(i+1, utils.format_vector(P_ck_x[i])))\n",
    "    return P_ck_x\n",
    "\n",
    "def calc_risk_prob(C, Lambda, X, verbose=True):\n",
    "    P_ck_x = calc_conditional_prob(C, X, Sigma=None, verbose=verbose)\n",
    "    \n",
    "    n_classes = len(P_ck_x)\n",
    "    n_actions = Lambda.shape[1]\n",
    "    R_ai_x = []\n",
    "    for i in range(n_actions):\n",
    "        lambda_i = Lambda[i,:]\n",
    "        R_ai_x.append(0.0)\n",
    "        for k in range(n_classes):\n",
    "            R_ai_x[i] += lambda_i[k] * P_ck_x[k]\n",
    "    if verbose:\n",
    "        print('---')\n",
    "        for i in range(n_actions):\n",
    "            print('R(a{}|x): {}'.format(i+1, utils.format_vector(R_ai_x[i])))\n",
    "    return R_ai_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 3.1\n",
    "\n",
    "<img src=\"figures/homework-18/exercise-3.1.png\" width=\"600\" />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = np.array([[-1,  0, -0.5, -1.5, -2,  0,   -1],\n",
    "               [ 0, -1, -0.5, -1.5,  0, -2, -1.3]])\n",
    "\n",
    "c2 = np.array([[ 1, 1.3, 0.7,  2.5,  0],\n",
    "               [ 1, 0.7, 1.3,  1.0,  1]])\n",
    "\n",
    "X = np.array([[0, 1, -1,  0.7, -0.2],\n",
    "              [0, 1,  0, -0.2,  1.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the prior probabilities for the classes. We can compute the prior probability for each class $c_k$ as follows:\n",
    "\n",
    "$$\n",
    "P(c_k) = \\frac{N_k}{\\sum_l^K N_l}\n",
    "$$\n",
    "where $N_k$ is the number of samples in class $c_k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class $c_1$ has 7 samples and $c_2$ has 5 samples. In total, we have 12 samples. Therefore, $P(c_1) = 7/12=0.58$ and $P(c_2) = 5/12=0.42$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAesAAAAVCAYAAABmHMZ8AAAABHNCSVQICAgIfAhkiAAACElJREFUeJztnXmMFEUUxn+uqBwSb8QDL2ABwaCoeOMCgvGAYKImGs+oMUaNRA2KmjDxRo3ReMQgKl4xRrw1KooHup6JGjQoEmQUBEQORWEFhPWP9zrb9FT3dPf29BS99SWTZuvVV/W9ydT9ugAHBwcHBweHLRJPAcuAbvUW4uDg4ODg0EFwKNAKXBQn82HAJuBqg21v4HFgMbAOKAP3ATslFFRWQabP0gjeKcAMYBHQAvwMvAAcFZJ/MjATWKj5VwLfAJOAXTLi5FFHkXR1dF+COJe23/7FMfLnjazafBBx/D4deAD4GFiteZ+JUfZxwIvAEkTzEqTfOLnOHFt1FckX23RdQPhY5302Bjgva3nb+xO3MoiYAQwF9kA6Hw+9gU+BHsCrwI+abzgwFzgGWBHhnB9lYEek0QfxD3CPIX0yMEHreAVYDvQBxgKdgPOobMjrga+BObTtFByJTEgW678XtpOTRx1F0tXRffGjF/AdsDXSMC8BpobkrQeybPN+xPX7W2Aw0icsAvoDzwLnRJR9E3AL0j+8gXR6uwKHAB8gfUg9OLbqKpIvNuo6GBhnKANkwB8BvAmc6ksfCnwB3AjcHsKlEVlVTzHY3kFmAVcG0u/V9EfCCjWgrJ+46InMPpYiHYcfw7X+nw28ziHl3aachzPg5FFHkXSl4diqKy0HZKL8HjAfuBs7V9ZZtnkPSfweDvRVThPVV9ZnaJ53ge4G+zZ14tiqKw3H6UrOCcNnWtZYg+0H4BdkQmvEnUoeGUg/QNMXAA0BW3dk5ruG+GfcZZIN1kdo/a+G2FcDfycobzBtX3itOHnUUSRdaTi26orDuQqZGA8DStg3WGfd5j2k9buJ6MG6AZmwrwF2i6klD46tutJwnK7knDAMQn7PizAPyJPUfqKX0CmQ4QRkBft5IH2EPmcgDc2Pv4FmYDSy5TczptjtkO2sfRDnZwOzqNy/B5iHbDcORbYblvtsw5DO45WY9QKM0efsGnLyqCMNx1ZdaTi26qrGGYBMjO9HfvMjDHnqjVq0+Vr6fTSwPzAdWIXEtwwC/gW+RFYx9eDYqqtIvtiqKwqX6vMxzGNesz5HITtcmw3W3ZD99R+QwdOPfvr8KaTieUjDbSR+w+0JPB1IWwBcCHwUSF8JXIdsv81BBuYVyJnaWGT1cinhuBY5G9sBOUs8FulE78yQk0cdRdLVUX3phPzufwVuiCiv3si6zdfa78P1+TsSQ3BQwD4LCVj7I2eOrbqK5IutusLQBVmobiI8RuUrfQ4zGRuRZfcMg20K0dtV3vncxCoiPUxCZtW7A12R2ckjiPi1yBaiCeOQgdsfSTcPOLtKfUsDnLe07iw5edRRJF1pOLbqSsK5GZlJ+99gKGHfNnjWbb69fjcRvQ1+h9r/Q/qEkcjkaSDwtto+rAPHVl1F8sVWXWE4X/O+USVfCyFvRx2lBTxvsFVruLer/foYQqNwj5bzssE2AfmS7kXO07oCQ2gLgrkrRvm7A6chkayLlZ81J486iqQrDcdWXdU4Q5HfcPC3WmLLG6yTtPks/G4ierC+S+0bqZzsd0Ei8lvZfLKQB8dWXUXyxVZdYWjWfGOq5PsNaTcVOFgLMAVxeVGb14QU+qDaL6tSeTX00XKCr4M0afpLBk5X5JB+IzKIx8G+yLtx3yfQlpSTRx1F0pWGY6suE6cTMoDPQeI1/Chh32CdVZvPyu8mogfribTttJkwVe1X5cyxVVcajtOVnBPEgZpnIRGR3oqV+AKn/VGey/Rpushhrj4bQwrtq8+w86248DQEI0y9d9A+MHDWIof7Dch7bnHwC9J5DEQC1mrByaOOIulKw7FVl4mzPdJ+BiABKf4t80nKeVT/Nt0/kDeyavN5+e3p/TPEvkqfXXLm2KorDcfpSs4JolpgmYcG5C4Sb0zcLMBsCXIw3o9KeIPkaC3EHx3aHbkcoYXKKPKk8LYPgu9MezPysHB5L319grr21GfUF9ZeTh51pOHYqisNx1ZdQc46pIGaMASZaH6CdAhJokprhazafF5+z0K2DPsC21LZFwzSZzlnjq26iuSLrbqC6Izc3LeJ8DbhoR9yv8C3YRmmIzPcPgZbmgsSeiO3DvlfFB8I7GzIuy+yvdBKZbTomZq+FNgrYDsJcb6FzXcF+iMR50E00BYc0xywJeXkUUeRdKXh2KorLceEEtHbwdPUfkGMsrJE0jZvau9RKJHdNjhqawVuDaSPQvqIP5HVSt4cW3UVyRdbdfnhXbH7eojdjws17xVhGc7SDJcbbL2RkPVW5NWpO4D39e+5mLfPy2rfz5dWQrbD3kJud5qMTBJaNO+byKzFjwbk9axW5AKUJ5X3GvIFmc4JxgMbkNdKpqjex5Gbk1qRnYQD28nJo44i6erovoShRPSg9ZTao67ZrAWStvkyle09CiWi/R6HTFSm0RZtO9+XFryWuAdtE/5Zan8BWQ1tQG6fCiIPjq26iuSLrbr8+Jh4gWUAz2mZvcIybIusXr8IsfcCnkA6ofXIudz9mFfKYG68x6uQH5FZyAZk+/1d5H5v033lILP18ci222p1ZBkS/j7akH8Q8BCyjbBc8/+FvL9WCtGclJNHHUXS1dF9CUOJ6EHrG+Q3397/PCMNkrT5MtkO1p497FM2cHZGVv4LVO8KJGj2yAgdeXBs1VUkX2zVBRKzETewbAdk8Vr1oi8v4i1usJaDg0PtsCNy5h3n1UQHB4ctH1ciY/Bx1TJ2RmbPcfbVHRwcaosxyLGR6WzcwcGhWOiC3M8wPS5hGPJaRdJL+h0cHBwcHBzSYQBy/LNffWU4ODg4ODg4ODg4ODg4OBQN/wNRHS27gbZPvAAAAABJRU5ErkJggg==\n",
      "text/latex": [
       "$$\\left ( 0.5833333333333334, \\quad 0.4166666666666667\\right )$$"
      ],
      "text/plain": [
       "(0.5833333333333334, 0.4166666666666667)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N1 = c1.shape[1]\n",
    "N2 = c2.shape[1]\n",
    "N_sum = N1 + N2\n",
    "\n",
    "P_c1 = N1/N_sum\n",
    "P_c2 = N2/N_sum\n",
    "P_c1, P_c2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the class-conditional probabilities in multiple steps:\n",
    "$$\n",
    "p(\\mathbf{x} \\mid c_k) = \n",
    "\\frac\n",
    "  { \\exp( - \\lVert \\mathbf{x} - \\mu_k \\rVert_2)  }\n",
    "  {  \\sum_{l=1}^{K}  \\exp( - \\lVert \\mathbf{x} - \\mu_l \\rVert_2)   }\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Compute the mean vector associated with each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.85714286],\n",
       "       [-0.9       ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = np.mean(c1, axis=1).reshape(-1, 1)\n",
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.1],\n",
       "       [1. ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2 = np.mean(c2, axis=1).reshape(-1, 1)\n",
    "m2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Compute $\\exp( - \\lVert \\mathbf{x} - \\mu_1 \\rVert_2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28855859, 0.07016722, 0.40201441, 0.18136432, 0.0830477 ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1_numerator = np.exp(-np.linalg.norm(X - m1, axis=0))\n",
    "c1_numerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: compute $\\exp( - \\lVert \\mathbf{x} - \\mu_1 \\rVert_2)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.22613867, 0.90483742, 0.09769151, 0.2822644 , 0.24836923])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2_numerator = np.exp(-np.linalg.norm(X - m2, axis=0))\n",
    "c2_numerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Compute the class-condition probability for class 1:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x} \\mid c_1) = \n",
    "\\frac\n",
    "  { \\exp( - \\lVert \\mathbf{x} - \\mu_1 \\rVert_2)  }\n",
    "  {  \\sum_{k=1}^{K}  \\exp( - \\lVert \\mathbf{x} - \\mu_k \\rVert_2)   }\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5606375 , 0.07196604, 0.804502  , 0.39118439, 0.25058376])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_x_c1 = c1_numerator / (c1_numerator + c2_numerator)\n",
    "p_x_c1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Compute the class-condition probability for class 2:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x} \\mid c_2) = \n",
    "\\frac\n",
    "  { \\exp( - \\lVert \\mathbf{x} - \\mu_2 \\rVert_2)  }\n",
    "  {  \\sum_{k=1}^{K}  \\exp( - \\lVert \\mathbf{x} - \\mu_k \\rVert_2)   }\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4393625 , 0.92803396, 0.195498  , 0.60881561, 0.74941624])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_x_c2 = c2_numerator / (c1_numerator + c2_numerator)\n",
    "p_x_c2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7: We can now compute conditional probability, which has the following formula (Bayes' formula):\n",
    "\n",
    "$$\n",
    "P(c_k \\mid \\mathbf{x}) = \\frac{p(\\mathbf{x} \\mid c_k) P(c_k)}{p(\\mathbf{x})}\n",
    "$$\n",
    "where\n",
    "$$\n",
    "p(\\mathbf{x}) = \\sum_{k=1}^K p(\\mathbf{x} \\mid c_k) P(c_k)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $p(\\mathbf{x})$ is the same for when computing $P(c_k\\mid \\mathbf{x})$, it is not necessary to compute it when we want to use the conditional probability to classify new samples. Therefore, we omit the division:\n",
    "$$\n",
    "P(c_k \\mid \\mathbf{x}) = p(\\mathbf{x} \\mid c_k) P(c_k)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.32703854, 0.04198019, 0.46929284, 0.2281909 , 0.14617386])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_c1_x = p_x_c1 * P_c1\n",
    "P_c1_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18306771, 0.38668082, 0.0814575 , 0.25367317, 0.31225677])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_c2_x = p_x_c2 * P_c2\n",
    "P_c2_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 8: Once we have the condition probabilities, we can use Bayes' Decision Rule to classify our samples $X$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.32703854, 0.04198019, 0.46929284, 0.2281909 , 0.14617386],\n",
       "       [0.18306771, 0.38668082, 0.0814575 , 0.25367317, 0.31225677]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a matrix so we can easily compute argmin\n",
    "P_ck_x = np.concatenate([[P_c1_x], \n",
    "                         [P_c2_x]])\n",
    "P_ck_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Classification Result: \n",
       "$$\n",
       "\\mathbf{x}_1 \\to c_1  \\\\ \n",
       "\\mathbf{x}_2 \\to c_2  \\\\ \n",
       "\\mathbf{x}_3 \\to c_1  \\\\ \n",
       "\\mathbf{x}_4 \\to c_2  \\\\ \n",
       "\\mathbf{x}_5 \\to c_2  \\\\ \n",
       "$$"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_classification(P_ck_x, objective='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `calc_conditional_prob` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(c1): 0.5833333333333334\n",
      "P(c2): 0.4166666666666667\n",
      "---\n",
      "p(x|c1): [ 0.5606,  0.0720,  0.8045,  0.3912,  0.2506]\n",
      "p(x|c2): [ 0.4394,  0.9280,  0.1955,  0.6088,  0.7494]\n",
      "---\n",
      "P(c1|x): [ 0.3270,  0.0420,  0.4693,  0.2282,  0.1462]\n",
      "P(c2|x): [ 0.1831,  0.3867,  0.0815,  0.2537,  0.3123]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Classification Result: \n",
       "$$\n",
       "\\mathbf{x}_1 \\to c_1  \\\\ \n",
       "\\mathbf{x}_2 \\to c_2  \\\\ \n",
       "\\mathbf{x}_3 \\to c_1  \\\\ \n",
       "\\mathbf{x}_4 \\to c_2  \\\\ \n",
       "\\mathbf{x}_5 \\to c_2  \\\\ \n",
       "$$"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1 = np.array([[-1,  0, -0.5, -1.5, -2,  0,   -1],\n",
    "               [ 0, -1, -0.5, -1.5,  0, -2, -1.3]])\n",
    "\n",
    "c2 = np.array([[ 1, 1.3, 0.7,  2.5,  0],\n",
    "               [ 1, 0.7, 1.3,  1.0,  1]])\n",
    "\n",
    "X = np.array([[0, 1, -1,  0.7, -0.2],\n",
    "              [0, 1,  0, -0.2,  1.5]])\n",
    "\n",
    "P_ck_x = calc_conditional_prob([c1, c2], X)\n",
    "\n",
    "print_classification(P_ck_x, objective='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ---\n",
    "## Exercise 3.2\n",
    "\n",
    "<img src=\"figures/homework-18/exercise-3.2.png\" width=\"600\" />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The risk of taking action $\\alpha_i$ given the observation $\\mathbf{x}$ as follows:\n",
    "\n",
    "$$\n",
    "R(\\alpha_i \\mid \\mathbf{x}) = \n",
    " \\sum_{k=1}^K \\lambda(\\alpha_i \\mid c_k) P(c_k \\mid \\mathbf{x})\n",
    "$$\n",
    "\n",
    "The loss function $\\lambda(\\alpha_i \\mid c_k)$ is given by an $A \\times K$ matrix $\\Lambda$, where $A$ is the number of actions and $K$ is the number of classes. Here we assume that $\\lambda(\\alpha_i, c_k)$ corresponds to the $i$th row and $k$th column in the matrix $\\Lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(c1): 0.5833333333333334\n",
      "P(c2): 0.4166666666666667\n",
      "---\n",
      "p(x|c1): [ 0.5606,  0.0720,  0.8045,  0.3912,  0.2506]\n",
      "p(x|c2): [ 0.4394,  0.9280,  0.1955,  0.6088,  0.7494]\n",
      "---\n",
      "P(c1|x): [ 0.3270,  0.0420,  0.4693,  0.2282,  0.1462]\n",
      "P(c2|x): [ 0.1831,  0.3867,  0.0815,  0.2537,  0.3123]\n",
      "---\n",
      "R(a1|x): [ 0.1831,  0.3867,  0.0815,  0.2537,  0.3123]\n",
      "R(a2|x): [ 0.3270,  0.0420,  0.4693,  0.2282,  0.1462]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Classification Result: \n",
       "$$\n",
       "\\mathbf{x}_1 \\to c_1  \\\\ \n",
       "\\mathbf{x}_2 \\to c_2  \\\\ \n",
       "\\mathbf{x}_3 \\to c_1  \\\\ \n",
       "\\mathbf{x}_4 \\to c_2  \\\\ \n",
       "\\mathbf{x}_5 \\to c_2  \\\\ \n",
       "$$"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def solve_3_2():\n",
    "    c1 = np.array([[-1,  0, -0.5, -1.5, -2,  0,   -1],\n",
    "                   [ 0, -1, -0.5, -1.5,  0, -2, -1.3]])\n",
    "\n",
    "    c2 = np.array([[ 1, 1.3, 0.7,  2.5,  0],\n",
    "                   [ 1, 0.7, 1.3,  1.0,  1]])\n",
    "\n",
    "    X = np.array([[0, 1, -1,  0.7, -0.2],\n",
    "                  [0, 1,  0, -0.2,  1.5]])\n",
    "    Lambda = np.array([[0, 1],\n",
    "                       [1, 0]])\n",
    "    R_ai_x = calc_risk_prob([c1, c2], Lambda, X)\n",
    "    return print_classification(R_ai_x, objective='min')\n",
    "solve_3_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 3.3\n",
    "\n",
    "<img src=\"figures/homework-18/exercise-3.3.png\" width=\"600\" />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(c1): 0.5833333333333334\n",
      "P(c2): 0.4166666666666667\n",
      "---\n",
      "p(x|c1): [ 0.5606,  0.0720,  0.8045,  0.3912,  0.2506]\n",
      "p(x|c2): [ 0.4394,  0.9280,  0.1955,  0.6088,  0.7494]\n",
      "---\n",
      "P(c1|x): [ 0.3270,  0.0420,  0.4693,  0.2282,  0.1462]\n",
      "P(c2|x): [ 0.1831,  0.3867,  0.0815,  0.2537,  0.3123]\n",
      "---\n",
      "R(a1|x): [ 0.2446,  0.3219,  0.2060,  0.2714,  0.2937]\n",
      "R(a2|x): [ 0.2655,  0.1067,  0.3448,  0.2105,  0.1648]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Classification Result: \n",
       "$$\n",
       "\\mathbf{x}_1 \\to c_1  \\\\ \n",
       "\\mathbf{x}_2 \\to c_2  \\\\ \n",
       "\\mathbf{x}_3 \\to c_1  \\\\ \n",
       "\\mathbf{x}_4 \\to c_2  \\\\ \n",
       "\\mathbf{x}_5 \\to c_2  \\\\ \n",
       "$$"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def solve_3_3():\n",
    "    c1 = np.array([[-1,  0, -0.5, -1.5, -2,  0,   -1],\n",
    "                   [ 0, -1, -0.5, -1.5,  0, -2, -1.3]])\n",
    "\n",
    "    c2 = np.array([[ 1, 1.3, 0.7,  2.5,  0],\n",
    "                   [ 1, 0.7, 1.3,  1.0,  1]])\n",
    "\n",
    "    X = np.array([[0, 1, -1,  0.7, -0.2],\n",
    "                  [0, 1,  0, -0.2,  1.5]])\n",
    "    Lambda = np.array([[0.3, 0.8],\n",
    "                       [0.7, 0.2]])\n",
    "    R_ai_x = calc_risk_prob([c1, c2], Lambda, X)\n",
    "    return print_classification(R_ai_x, objective='min')\n",
    "solve_3_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 3.3 (solution manual)\n",
    "\n",
    "<img src=\"figures/homework-18/exercise-3.3-extra.png\" width=\"600\" />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(c1): 0.5833333333333334\n",
      "P(c2): 0.4166666666666667\n",
      "---\n",
      "p(x|c1): [ 0.5606,  0.0720,  0.8045,  0.3912,  0.2506]\n",
      "p(x|c2): [ 0.4394,  0.9280,  0.1955,  0.6088,  0.7494]\n",
      "---\n",
      "P(c1|x): [ 0.3270,  0.0420,  0.4693,  0.2282,  0.1462]\n",
      "P(c2|x): [ 0.1831,  0.3867,  0.0815,  0.2537,  0.3123]\n",
      "---\n",
      "R(a1|x): [ 0.2773,  0.3261,  0.2529,  0.2942,  0.3083]\n",
      "R(a2|x): [ 0.2328,  0.1025,  0.2979,  0.1876,  0.1502]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Classification Result: \n",
       "$$\n",
       "\\mathbf{x}_1 \\to c_2  \\\\ \n",
       "\\mathbf{x}_2 \\to c_2  \\\\ \n",
       "\\mathbf{x}_3 \\to c_1  \\\\ \n",
       "\\mathbf{x}_4 \\to c_2  \\\\ \n",
       "\\mathbf{x}_5 \\to c_2  \\\\ \n",
       "$$"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def solve_3_3_sol_manual():\n",
    "    c1 = np.array([[-1,  0, -0.5, -1.5, -2,  0,   -1],\n",
    "                   [ 0, -1, -0.5, -1.5,  0, -2, -1.3]])\n",
    "\n",
    "    c2 = np.array([[ 1, 1.3, 0.7,  2.5,  0],\n",
    "                   [ 1, 0.7, 1.3,  1.0,  1]])\n",
    "\n",
    "    X = np.array([[0, 1, -1,  0.7, -0.2],\n",
    "                  [0, 1,  0, -0.2,  1.5]])\n",
    "    Lambda = np.array([[0.4, 0.8],\n",
    "                       [0.6, 0.2]])\n",
    "    R_ai_x = calc_risk_prob([c1, c2], Lambda, X)\n",
    "    return print_classification(R_ai_x, objective='min')\n",
    "solve_3_3_sol_manual()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 3.4\n",
    "\n",
    "<img src=\"figures/homework-18/exercise-3.4a.png\" width=\"600\" />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"figures/homework-18/exercise-3.4b.png\" width=\"600\" />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equation 3.69 only holds when covariance matrix is the identity matrix. The Eclidean distance can be expressed as the Mahalanobis distance if we let $\\Sigma = \\mathbf{I}$:\n",
    "\n",
    "$$\n",
    "\\lVert \\mathbf{x} - \\mathbf{m}_k  \\rVert_2 = \n",
    "  \\sqrt{\n",
    "  (\\mathbf{x} - \\mathbf{m}_k)^T\n",
    "  \\mathbf{\\Sigma}^{-1}\n",
    "  (\\mathbf{x} - \\mathbf{m}_k)\n",
    "  }\n",
    "$$\n",
    "\n",
    "This means that when the covariance matrix is the identity matrix, the Mahalanobis distance reduces to Euclidean distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When given another covariance matrix, we need to generalise the likelihood of $\\mathbf{x}$ given $c_k$ as follows:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x} \\mid c_k) = \n",
    "\\frac\n",
    "  { \\exp( - (\\mathbf{x} - \\mathbf{m}_k)^T\n",
    "  \\mathbf{\\Sigma}^{-1}\n",
    "  (\\mathbf{x} - \\mathbf{m}_k)   )  }\n",
    "  {  \\sum_{l=1}^{K}  \\exp( - \n",
    "    (\\mathbf{x} - \\mathbf{m}_k)^T\n",
    "    \\mathbf{\\Sigma}^{-1}\n",
    "    (\\mathbf{x} - \\mathbf{m}_k)\n",
    "  )   }\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(c1): 0.5833333333333334\n",
      "P(c2): 0.4166666666666667\n",
      "---\n",
      "p(x|c1): [ 0.6388,  0.0053,  0.9888,  0.1431,  0.1829]\n",
      "p(x|c2): [ 0.3612,  0.9947,  0.0112,  0.8569,  0.8171]\n",
      "---\n",
      "P(c1|x): [ 0.3727,  0.0031,  0.5768,  0.0835,  0.1067]\n",
      "P(c2|x): [ 0.1505,  0.4145,  0.0046,  0.3570,  0.3405]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Classification Result: \n",
       "$$\n",
       "\\mathbf{x}_1 \\to c_1  \\\\ \n",
       "\\mathbf{x}_2 \\to c_2  \\\\ \n",
       "\\mathbf{x}_3 \\to c_1  \\\\ \n",
       "\\mathbf{x}_4 \\to c_2  \\\\ \n",
       "\\mathbf{x}_5 \\to c_2  \\\\ \n",
       "$$"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def solve_3_4():\n",
    "    c1 = np.array([[-1,  0, -0.5, -1.5, -2,  0,   -1],\n",
    "                   [ 0, -1, -0.5, -1.5,  0, -2, -1.3]])\n",
    "\n",
    "    c2 = np.array([[ 1, 1.3, 0.7,  2.5,  0],\n",
    "                   [ 1, 0.7, 1.3,  1.0,  1]])\n",
    "\n",
    "    X = np.array([[0, 1, -1,  0.7, -0.2],\n",
    "                  [0, 1,  0, -0.2,  1.5]])\n",
    "    sigma_c1 = np.array([[1, 0],\n",
    "                         [0, 2]])\n",
    "    sigma_c2 = np.array([[1, 0],\n",
    "                         [0, 2]])\n",
    "    P_ck_x = calc_conditional_prob([c1, c2], X, [sigma_c1, sigma_c2])\n",
    "    \n",
    "    return print_classification(P_ck_x, objective='max')\n",
    "\n",
    "solve_3_4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 3.5\n",
    "\n",
    "<img src=\"figures/homework-18/exercise-3.5.png\" width=\"600\" />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(c1): 0.5833333333333334\n",
      "P(c2): 0.4166666666666667\n",
      "---\n",
      "p(x|c1): [ 0.5955,  0.0104,  0.9121,  0.4058,  0.0238]\n",
      "p(x|c2): [ 0.4045,  0.9896,  0.0879,  0.5942,  0.9762]\n",
      "---\n",
      "P(c1|x): [ 0.3474,  0.0060,  0.5321,  0.2367,  0.0139]\n",
      "P(c2|x): [ 0.1685,  0.4124,  0.0366,  0.2476,  0.4067]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Classification Result: \n",
       "$$\n",
       "\\mathbf{x}_1 \\to c_1  \\\\ \n",
       "\\mathbf{x}_2 \\to c_2  \\\\ \n",
       "\\mathbf{x}_3 \\to c_1  \\\\ \n",
       "\\mathbf{x}_4 \\to c_2  \\\\ \n",
       "\\mathbf{x}_5 \\to c_2  \\\\ \n",
       "$$"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def solve_3_5():\n",
    "    c1 = np.array([[-1,  0, -0.5, -1.5, -2,  0,   -1],\n",
    "                   [ 0, -1, -0.5, -1.5,  0, -2, -1.3]])\n",
    "\n",
    "    c2 = np.array([[ 1, 1.3, 0.7,  2.5,  0],\n",
    "                   [ 1, 0.7, 1.3,  1.0,  1]])\n",
    "\n",
    "    X = np.array([[0, 1, -1,  0.7, -0.2],\n",
    "                  [0, 1,  0, -0.2,  1.5]])\n",
    "\n",
    "    # Compute the actual covariance matrix of c1\n",
    "    mu1 = np.mean(c1, axis=1).reshape(-1, 1)\n",
    "    sigma_c1 = np.dot(c1 - mu1, (c1 - mu1).T)\n",
    "    \n",
    "    # Compute the actual covariance matrix of c2\n",
    "    mu2 = np.mean(c2, axis=1).reshape(-1, 1)\n",
    "    sigma_c2 = np.dot(c2 - mu2, (c2 - mu2).T)\n",
    "    \n",
    "    # Compute Sigma\n",
    "    sigma = (sigma_c1+sigma_c2)/2\n",
    "    \n",
    "    P_ck_x = calc_conditional_prob([c1, c2], X, [sigma, sigma])\n",
    "    \n",
    "    return print_classification(P_ck_x, objective='max')\n",
    "\n",
    "solve_3_5()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
